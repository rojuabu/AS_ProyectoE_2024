---
title: "AS_ProyectoE_2024"
author:
  - name: Marcos Rosique
  - name: Pablo Selma
  - name: Víctor Mateu Izquierdo
  - name: Marc Velasco Mateu
  - name: Carlos Ribes García
  - name: Rodrigo Juanes
date: "2024-12-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(magick)
library(wavelets)
library(waveslim)
library(raster)
library(grid)
library(gridExtra)
library(av)
```

# 1. Importación de imágenes y preacondicionamiento.

### a. Importación de imágenes, transformación a matrices RGB y normalización de tamaños.

Las transformadas wavelet han emergido como una herramienta poderosa en el análisis y procesamiento de imágenes, gracias a su capacidad para representar información en diferentes escalas y resoluciones. A diferencia de las transformadas tradicionales, como la de Fourier, las wavelets permiten descomponer una imagen en componentes de frecuencia y localización espacial, proporcionando una representación jerárquica y altamente eficiente.

Para ello, se importan las imágenes a analizar mediante la siguiente función para posteriormente hacer un redimensionamiento de estas a imágenes con dimensiones que son potencia de 2, ya que, la transformada Wavelet descompone las componentes en estas potencias.

Por otro lado, las transformamos en arrays que contienen los distintos canales RGB y para aquellas fotos con filtro blanco y negro extraemos solo un canal, puesto que todos son iguales.
```{r 1_1_1_funcion_procesar_imagen, echo=TRUE}
# Definir una función para redimensionar y convertir en array
procesar_imagen <- function(ruta_imagen, tamano) {
  imagen <- image_read(ruta_imagen)
  imagen_redimensionada <- image_scale(imagen, tamano)
  array_imagen <- as.integer(image_data(imagen_redimensionada))
  return(array_imagen)
}
```

```{r 1_1_2_procesar_imagenes, echo=TRUE}
# Aplicar la función a cada imagen
arbol_01 <- procesar_imagen("./images/arbol_01.jpg", "1024x1024!")
arbol_03 <- procesar_imagen("./images/arbol_03.jpg", "1024x1024!")
perro_01 <- procesar_imagen("./images/perro_01.jpg", "1024x1024!")
flor_01 <- procesar_imagen("./images/flor_01.jpg", "1024x1024!")
flor_02 <- procesar_imagen("./images/flor_02.jpg", "1024x1024!")
flor_04_filtro <- procesar_imagen("./images/flor_04_filtro.jpg", "1024x1024!")
flor_05_filtro <- procesar_imagen("./images/flor_05_filtro.jpg", "1024x1024!")
peluche_01_filtro <- procesar_imagen("./images/peluche_01_filtro.jpg", "1024x1024!")
planta_01 <- procesar_imagen("./images/planta_01.jpg", "1024x1024!")
pinas_01 <- procesar_imagen("./images/piñas_01.jpg", "1024x1024!")
gato_01 <- procesar_imagen("./images/gato_01.jpg", "1024x1024!")
gato_02_filtro <- procesar_imagen("./images/gato_02_filtro.jpg", "1024x1024!")


# Extraer solo un canal RGB para aquellas imágenes con filtro blanco y negro 
flor_04_filtro <- flor_04_filtro[, , 1]
flor_05_filtro <- flor_05_filtro[, , 1]
peluche_01_filtro <- peluche_01_filtro[, , 1]
gato_02_filtro <- gato_02_filtro[, , 1]
```

Este sería un ejemplo de como convertir de array a imagen:
```{r 1_1_3_ejemplo_array_a_imagen, echo=TRUE, warning=FALSE}
# Crear un objeto raster de la imagen
imagen_raster <- brick(gato_01)

# Visualizar la imagen en color usando plotRGB
plotRGB(imagen_raster, r = 1, g = 2, b = 3, main = "Imagen Redimensionada 1024x1024")
```


# 2. Aplicación de la transformada wavelet:

Las wavelets son funciones matemáticas que permiten descomponer una señal en sus componentes de frecuencia a diferentes escalas, proporcionando una representación conjunta en el dominio del tiempo y la frecuencia.

Para el caso de una imagen, la transformada wavelet descompone la imagen en diferentes niveles de detalle y frecuencias espaciales, dividiendo la imagen en coeficientes de baja frecuencia (aproximación) y alta frecuencia (detalle) en direcciones horizontal, vertical y diagonal. Esto permite analizar características específicas como bordes, texturas y estructuras a distintas resoluciones, facilitando aplicaciones como la compresión, eliminación de ruido y detección de bordes en imágenes.

## 2.1. Funciones de transformada wavelet

### a. Transformada en una dimensión aplicada por filas y columnas de la matriz

En la primera función se aplica para cada canal la transformada wavelet unidimensional a cada fila de su matriz de píxeles. En el caso de las imágenes en blanco y negro esta transformada se aplica sobre su matriz general, pues poseen solo un canal.

La segunda función es lo mismo pero por columnas de la matriz.
```{r 1_2_1_wavelet_1d_por_filas, echo=TRUE}
# Función para aplicar wavelet a cada fila de una matriz de canales
aplicar_dwt_filas <- function(matriz, filtro_wavelet = "haar") {
  lapply(1:nrow(matriz), function(i) wavelets::dwt(as.numeric(matriz[i, ]), filter = filtro_wavelet, n.levels=2))
}

# Función para extraer canales y aplicar wavelet a cada fila
extraccion_wavelet_filas <- function(array_imagen, filtro_wavelet = "haar") {
  wavelet_filas_R <- aplicar_dwt_filas(array_imagen[, , 1], filtro_wavelet)
  wavelet_filas_G <- aplicar_dwt_filas(array_imagen[, , 2], filtro_wavelet)
  wavelet_filas_B <- aplicar_dwt_filas(array_imagen[, , 3], filtro_wavelet)
  
  return(list(wavelet_filas_R = wavelet_filas_R, wavelet_filas_G = wavelet_filas_G, wavelet_filas_B = wavelet_filas_B))
}



# Función para aplicar wavelet a cada columna de una matriz de canales
aplicar_dwt_columnas <- function(matriz, filtro_wavelet = "haar") {
 lapply(1:ncol(matriz), function(j) wavelets::dwt(as.numeric(matriz[ , j]), filter = filtro_wavelet, n.levels=2))
}
# Función para extraer canales y aplicar wavelet a cada columna
extraccion_wavelet_columnas <- function(array_imagen, filtro_wavelet = "haar") {
  wavelet_columnas_R <- aplicar_dwt_columnas(array_imagen[, , 1], filtro_wavelet)
  wavelet_columnas_G <- aplicar_dwt_columnas(array_imagen[, , 2], filtro_wavelet)
  wavelet_columnas_B <- aplicar_dwt_columnas(array_imagen[, , 3], filtro_wavelet)
  
  return(list(wavelet_columnas_R = wavelet_columnas_R, wavelet_columnas_G = wavelet_columnas_G, wavelet_columnas_B = wavelet_columnas_B))
}
```


### b. Transformada en una dimensión aplicada al vector que concatena todas las filas de la matriz

Las matrices RGB se convierten en vectores numéricos para posteriormente concatenarlos y aplicar la DWT unidimensional a cada vector de color.

```{r 1_2_2_wavelet_1d_concatenado, echo=TRUE}
# Función para aplicar DWT en una dimensión a una imagen
aplicar_dwt_vector <- function(imagen, bn = FALSE, filtro_wavelet = "haar", nivel = 2) {
  # Convertir cada canal de la imagen en un vector unidimensional
  vector_R <- as.numeric(imagen[, , 1])
  vector_G <- as.numeric(imagen[, , 2])
  vector_B <- as.numeric(imagen[, , 3])
  
  # Concatenar los vectores de cada canal en un solo vector unidimensional
  
  # Aplicar la transformada wavelet al vector concatenado
  resultado_wavelet_R <- wavelets::dwt(vector_R, filter = filtro_wavelet, n.levels = nivel)
  resultado_wavelet_G <- wavelets::dwt(vector_G, filter = filtro_wavelet, n.levels = nivel)
  resultado_wavelet_B <- wavelets::dwt(vector_B, filter = filtro_wavelet, n.levels = nivel)
  
  return(list(  resultado_wavelet_R , resultado_wavelet_R , resultado_wavelet_R))
}

```

```{r, include=FALSE}
# Aplicar la función a la imagen
dwt_vector_arbol_01 <- aplicar_dwt_vector(arbol_01)
```


### c. Transformada en dos dimensiones aplicada por canales RGB

Para la aplicación de wavelets en dos dimensiones hay que tener en cuenta los siguientes términos:

+ LL: Baja frecuencia en la dirección horizontal y en la dirección vertical. Contiene las bajas frecuencias de la imagen, nos da una versión suavizada.

+ LH: Baja frecuencia en la dirección horizontal y alta frecuencia en la dirección vertical. Captura detalles finos horizontales (bordes verticales) en la imagen.

+ HL: Alta frecuencia en la dirección horizontal y baja frecuencia en la dirección vertical. Captura detalles finos verticales (bordes horizontales) en la imagen.

+ HH: Alta frecuencia tanto en la dirección horizontal como en la dirección vertical. Captura detalles finos diagonales en la imagen.


La siguiente función aplica la transformada wavelet 2D a cada canal de color (R, G, B) de la imagen individualmente. Cada canal se descompone independientemente en sus componentes de frecuencia por lo que puede ser beneficioso si se desea analizar la información de color por separado.

Por otro lado, a la hora de reconstruir la imagen, cada canal de color (R, G, B) se transforma y se reconstruye de manera independiente, teniendo como consecuencia que las interdependencias entre los canales no se tienen en cuenta durante la transformada.

```{r 1_2_3_wavelet_2d_RGB_por_separado, echo = TRUE}
# Función para aplicar DWT en 2D a cada canal de la imagen
aplicar_dwt2d_a_matriz <- function(array_imagen, wf = "haar") {
  wavelet_R <- dwt.2d(array_imagen[, , 1], wf)
  wavelet_G <- dwt.2d(array_imagen[, , 2], wf)
  wavelet_B <- dwt.2d(array_imagen[, , 3], wf)
  
  return(list(wavelet_R = wavelet_R, wavelet_G = wavelet_G, wavelet_B = wavelet_B))
}
```

```{r, include=FALSE}
# Aplicar la función a la imagen
dwt2d_RGB_arbol_01<- aplicar_dwt2d_a_matriz(arbol_01)
```


### d. Transformada en dos dimensiones aplicada a una imagen completa

En este caso la transformada wavelet 2D se aplica directamente a la imagen completa con la función `dwt.2d`, considerando todos los canales de color conjuntamente. De esta manera puede capturar mejor las correlaciones entre los canales de color.

Se obtiene un único conjunto de coeficientes wavelet que representa toda la imagen, lo que puede ser útil si se está interesado en la estructura general de la imagen en lugar de análisis específicos de color.

Por otra parte, a la hora de reconstruir la imagen todos los canales de color se consideran conjuntamente durante la transformada capturando mejor las correlaciones entre los canales de color RGB.

```{r 1_2_4_wavelet_2d_completa, include=FALSE}
# Aplicación a la imagen globalmente
dwt2d_arbol_01 <- dwt.2d(arbol_01, "haar", J = 2)
```


## 2.2. Ejemplo de transformada wavelet unidimensional

Aplicando algunas de las funciones unidimensionales anteriormente mencionadas podemos realizar las transformadas wavelet 2D definiendo filtros de paso bajo y alto para filas y columnas y combinándolos.
Realizaremos la demostración sobre una imagen en blanco y negro para tener que ocuparnos de una sola matriz (grises), en vez de tres (rojo, verde, azul) como sucedería con una imagen a color. Sin embargo, notamos que el siguiente método también se puede aplicar análogamente a imágenes a color.


```{r 1_2_5_dwt2d_casera_1, echo=FALSE}
# Función análoga a extraccion_dwt_filas() pero para imágenes con un sólo canal de color (gris)
extraccion_dwt_filas_byn <- function(array_imagen, filtro_wavelet = "haar") {
  wavelet_filas <- aplicar_dwt_filas(array_imagen[, ], filtro_wavelet)
  
  return(list(wavelet_filas = wavelet_filas))
}

# Función análoga a extraccion_dwt_columnas_() pero para imágenes con un sólo canal de color
extraccion_dwt_columnas_byn <- function(array_imagen, filtro_wavelet = "haar") {
  wavelet_columnas <- aplicar_dwt_columnas(array_imagen[, ], filtro_wavelet)
  
  return(list(wavelet_columnas = wavelet_columnas))
}
```


```{r 1_2_5_dwt2d_casera_2, echo=FALSE}
# Definimos funcion de filtro de paso bajo
filtro_filas_paso_bajo <- function(copia, copia_2){
  
  # Obtenemos las dimensiones de los Detalles de la transformada wavelet
  nrow_f1 <- dim(copia$wavelet_filas[[1]]@W$W1)[1]
  ncol_f1 <- dim(copia$wavelet_filas[[1]]@W$W1)[2]
  nrow_f2 <- dim(copia$wavelet_filas[[1]]@W$W2)[1]
  ncol_f2 <- dim(copia$wavelet_filas[[1]]@W$W2)[2]
  
  # Dichas dimensiones las utilizamos para sustituir los Detalles con matrices de ceros con las mismas dimensiones (esta táctica también se utilizará en los siguientes tres filtros) 
  for (i in 1:length(copia$wavelet_filas)){
  copia$wavelet_filas[[i]]@W$W1 <- matrix(0, nrow=nrow_f1, ncol=ncol_f1)
  copia$wavelet_filas[[i]]@W$W2 <- matrix(0, nrow=nrow_f2, ncol=ncol_f2)
  
  copia_2[i, ] <- wavelets::idwt(copia$wavelet_filas[[i]])
  }
  return(copia_2)
}
```


```{r 1_2_5_dwt2d_casera_3, echo=FALSE}
filtro_columnas_paso_bajo <- function(copia, copia_2){

  nrow_c1 <- dim(copia$wavelet_columnas[[1]]@W$W1)[1]
  ncol_c1 <- dim(copia$wavelet_columnas[[1]]@W$W1)[2]
  nrow_c2 <- dim(copia$wavelet_columnas[[1]]@W$W2)[1]
  ncol_c2 <- dim(copia$wavelet_columnas[[1]]@W$W2)[2]
  
  for (j in 1:length(copia$wavelet_columnas)){
  copia$wavelet_columnas[[j]]@W$W1 <- matrix(0, nrow=nrow_c1, ncol=ncol_c1)
  copia$wavelet_columnas[[j]]@W$W2 <- matrix(0, nrow=nrow_c2, ncol=ncol_c2)
  
  copia_2[, j] <- wavelets::idwt(copia$wavelet_columnas[[j]])
  }
  return(copia_2)
}
```


```{r 1_2_5_dwt2d_casera_4, echo=FALSE}
# Definimos funcion de filtro de paso alto
filtro_filas_paso_alto <- function(copia, copia_2){

  # En este filtro y en el siguiente, en vez de anular los Detalles, anularemos las Aproximaciones
  nrow_f1 <- dim(copia$wavelet_filas[[1]]@V$V1)[1]
  ncol_f1 <- dim(copia$wavelet_filas[[1]]@V$V1)[2]
  nrow_f2 <- dim(copia$wavelet_filas[[1]]@V$V2)[1]
  ncol_f2 <- dim(copia$wavelet_filas[[1]]@V$V2)[2]
  
  for (i in 1:length(copia$wavelet_filas)){
  copia$wavelet_filas[[i]]@V$V1 <- matrix(0, nrow=nrow_f1, ncol=ncol_f1)
  copia$wavelet_filas[[i]]@V$V2 <- matrix(0, nrow=nrow_f2, ncol=ncol_f2)
  
  copia_2[i, ] <- wavelets::idwt(copia$wavelet_filas[[i]])
}
  return(copia_2)
}
```


```{r 1_2_5_dwt2d_casera_5, echo=FALSE}
filtro_columnas_paso_alto <- function(copia, copia_2){

  nrow_c1 <- dim(copia$wavelet_columnas[[1]]@V$V1)[1]
  ncol_c1 <- dim(copia$wavelet_columnas[[1]]@V$V1)[2]
  nrow_c2 <- dim(copia$wavelet_columnas[[1]]@V$V2)[1]
  ncol_c2 <- dim(copia$wavelet_columnas[[1]]@V$V2)[2]
  
  for (j in 1:length(copia$wavelet_columnas)){
  copia$wavelet_columnas[[j]]@V$V1 <- matrix(0, nrow=nrow_c1, ncol=ncol_c1)
  copia$wavelet_columnas[[j]]@V$V2 <- matrix(0, nrow=nrow_c2, ncol=ncol_c2)
  
  copia_2[, j] <- wavelets::idwt(copia$wavelet_columnas[[j]])
}
  return(copia_2)
}
```


```{r 1_2_5_dwt2d_casera_6, echo=FALSE}
# Obtenemos los detalles horizontales de la imagen, LH. Básicamente, aplicamos un filtro de paso bajo a las filas y un filtro de paso alto a las columnas
LH_detalles_horizontales <- function(matriz_imagen){
  copia <- extraccion_dwt_filas_byn(matriz_imagen)
  matriz_ceros <- matrix(0, nrow=dim(matriz_imagen)[1], ncol=dim(matriz_imagen)[2])
  
  copia_2 <- filtro_filas_paso_bajo(copia, matriz_ceros)
  copia_2 <- extraccion_dwt_columnas_byn(copia_2)
  
  copia_3 <- filtro_columnas_paso_alto(copia_2, matriz_ceros) #LH: detalles horizontales
  return(copia_3)
}
```

```{r 1_2_5_dwt2d_casera_7, echo=FALSE}
copia_LH <- LH_detalles_horizontales(flor_05_filtro)

# Comparamos con la imagen original (estas líneas están comentadas para que el documento final no se llene de imágenes)

# grid.newpage()
# grid.raster(flor_05_filtro/255)

#grid.newpage() # Función necesaria para mostrar imágenes con grid.raster (usada a continuación)
copia_LH <- (copia_LH - min(copia_LH))/(max(copia_LH) - min(copia_LH)) # Se normalizan los elementos para que se encuentren en el intervalo [0, 1]
#grid.raster(copia_LH) # Mostramos la imagen. 

# Nota: A la función grid.raster() se le asigna una matriz y te genera una imagen. Si la la profundidad de la matriz es 1 (es decir sólo tiene filas y columnas) interpreta que la imagen está en tonos de grises; si su profundidad es 3, interpreta que la imagen está en RGB asignando a cada profundidad tonos de rojo, verde y azul, respectivamente.
```

```{r 1_2_5_dwt2d_casera_8, echo=FALSE}
#Obtenemos los detalles verticales de la imagen, HL. Realizamos un filtro de paso alto a las filas y un filtro de paso bajo a las columnas
HL_detalles_verticales <- function(matriz_imagen){
  copia <- extraccion_dwt_filas_byn(matriz_imagen)
  matriz_ceros <- matrix(0, nrow=dim(matriz_imagen)[1], ncol=dim(matriz_imagen)[2])
  
  copia_2 <- filtro_filas_paso_alto(copia, matriz_ceros)
  copia_2 <- extraccion_dwt_columnas_byn(copia_2)
  
  copia_3 <- filtro_columnas_paso_bajo(copia_2, matriz_ceros) #HL: detalles verticales
  return(copia_3)
}
```

```{r 1_2_5_dwt2d_casera_9, echo=FALSE}
copia_HL <- HL_detalles_verticales(flor_05_filtro)

# grid.newpage()
# grid.raster(flor_05_filtro/255)

#grid.newpage()
copia_HL <- (copia_HL - min(copia_HL))/(max(copia_HL) - min(copia_HL)) # Se normalizan los elementos para que se encuentren en el intervalo [0, 1]
#grid.raster(copia_HL)
```


```{r 1_2_5_dwt2d_casera_10, echo=FALSE}
# Obtenemos la imagen suavizada, LL. Aplicamos un filtro de paso bajo a las filas y un fitro de paso bajo a las columnas
LL_suavizado <- function(matriz_imagen){
  copia <- extraccion_dwt_filas_byn(matriz_imagen)
  matriz_ceros <- matrix(0, nrow=dim(matriz_imagen)[1], ncol=dim(matriz_imagen)[2])
  
  copia_2 <- filtro_filas_paso_bajo(copia, matriz_ceros)
  copia_2 <- extraccion_dwt_columnas_byn(copia_2)
  
  copia_3 <- filtro_columnas_paso_bajo(copia_2, matriz_ceros) #LL: suavizado
  return(copia_3)
}
```

```{r 1_2_5_dwt2d_casera_11, echo=FALSE}
copia_LL <- LL_suavizado(flor_05_filtro)

# grid.newpage()
# grid.raster(flor_05_filtro/255)

#grid.newpage()
#grid.raster(copia_LL/255) # Se divide entre 255 para que los elementos se encuentren en el intervalo [0, 1] (la matriz puede tener valores entre [0, 255], los transformamos al intervalo [0, 1] debido a que la función grid.raster trabaja con dicho intervalo)
```


```{r 1_2_5_dwt2d_casera_12, echo=FALSE}
# Obtenemos los detalles diagonales, HH. Realizamos un filtro de paso alto tanto a las filas como a las columnas.
HH_detalles_diagonales <- function(matriz_imagen){
  copia <- extraccion_dwt_filas_byn(matriz_imagen)
  matriz_ceros <- matrix(0, nrow=dim(matriz_imagen)[1], ncol=dim(matriz_imagen)[2])
  
  copia_2 <- filtro_filas_paso_alto(copia, matriz_ceros)
  copia_2 <- extraccion_dwt_columnas_byn(copia_2)
  
  copia_3 <- filtro_columnas_paso_alto(copia_2, matriz_ceros) #HH: detalles diagonales
  return(copia_3)
}
```

```{r 1_2_5_dwt2d_casera_13, echo=FALSE}
copia_HH <- HH_detalles_diagonales(flor_05_filtro)

# grid.newpage()
# grid.raster(flor_05_filtro/255)

#grid.newpage()
copia_HH <- (copia_HH - min(copia_HH))/(max(copia_HH) - min(copia_HH)) # Se normalizan los elementos para que se encuentren en el intervalo [0, 1]
#grid.raster(copia_HH)
```


```{r 1_2_6_plot_dwt_2d_casero, echo = FALSE}
# Función para fusionar 4 matrices n x n en una matriz 2n x 2n y representarla
fusionar_y_mostrar_imagenes <- function(imagen1, imagen2, imagen3, imagen4) {
  # Verificar que las imágenes tengan dimensiones compatibles
  if (!all(dim(imagen1) == dim(imagen2), dim(imagen2) == dim(imagen3), dim(imagen3) == dim(imagen4))) {
    stop("Las dimensiones de las imágenes deben ser iguales.")
  }
  
  n <- dim(imagen1)[1]  
  
  imagen_fusionada <- matrix(0, nrow = 2 * n, ncol = 2 * n)
  
  imagen_fusionada[1:n, 1:n] <- imagen1   # Cuadrante superior izquierdo
  imagen_fusionada[1:n, (n + 1):(2 * n)] <- imagen2  # Cuadrante superior derecho
  imagen_fusionada[(n + 1):(2 * n), 1:n] <- imagen3   # Cuadrante inferior izquierdo
  imagen_fusionada[(n + 1):(2 * n), (n + 1):(2 * n)] <- imagen4  # Cuadrante inferior derecho
  
  grid.newpage()
  
  # Mostrar la imagen fusionada
  grid.raster(imagen_fusionada, interpolate = TRUE)
  
  # Textos
  grid.text("HL", x = unit(0.35, "npc"), y = unit(0.95, "npc"), gp = gpar(fontsize = 16, fontface = "bold") )
  grid.text("HH", x = unit(0.65, "npc"), y = unit(0.95, "npc"), gp = gpar(fontsize = 16, fontface = "bold") )
  grid.text("LL", x = unit(0.35, "npc"), y = unit(0.45, "npc"), gp = gpar(fontsize = 16, fontface = "bold") )
  grid.text("LH", x = unit(0.65, "npc"), y = unit(0.45, "npc"), gp = gpar(fontsize = 16, fontface = "bold") )
}


fusionar_y_mostrar_imagenes(copia_HL, copia_HH, copia_LL/256, copia_LH)

```

La imagen anterior muestra la descomposición de una imagen de una flor mediante una Transformada Wavelet Discreta (DWT), la cual divide la información en cuatro subbandas que representan diferentes características de la imagen. La subbanda LL (Low-Low) contiene las componentes de baja frecuencia tanto en dirección horizontal como vertical, lo que permite capturar la mayor parte de la estructura y los patrones principales de la imagen, mientras que las subbandas HL (High-Low) y LH (Low-High) resaltan, respectivamente, los detalles y bordes predominantes en las direcciones horizontal y vertical. Por otro lado, la subbanda HH (High-High) incluye las componentes de alta frecuencia en ambas direcciones, lo cual permite destacar los detalles más finos y, en algunos casos, elementos de ruido. En conjunto, esta descomposición resulta especialmente útil para tareas de procesamiento de imágenes, ya que facilita el análisis, la compresión o la mejora de características específicas en cada subbanda.

# 3. Algoritmos de compresión

## 3.1 Algoritmos de compresión unidimensionales

### a. Reconstrucción de imagen para la transformada wavelet por filas.

Realizamos una función para aplicar un filtro de paso bajo por filas a los tres canales de color.
```{r 2_1_1_funcion_paso_bajo, echo=FALSE}
# Esta función es totalmente análoga a la función filtro_filas_paso_bajo() previamente creada.
# Sin embargo, su existencia se debe a que la forma que tiene la matriz transformada es ligeramente distinta:
# filtro_filas_paso_bajo:        copia$wavelet_filas[[1]]@W$W1
# filtro_filas_paso_bajo_color:  copia[[1]]@W$W1

filtro_filas_paso_bajo_color <- function(copia, copia_2){
  
  nrow_f1 <- dim(copia[[1]]@W$W1)[1]
  ncol_f1 <- dim(copia[[1]]@W$W1)[2]
  nrow_f2 <- dim(copia[[1]]@W$W2)[1]
  ncol_f2 <- dim(copia[[1]]@W$W2)[2]

  for (i in 1:length(copia)){
  copia[[i]]@W$W1 <- matrix(0, nrow=nrow_f1, ncol=ncol_f1)
  copia[[i]]@W$W2 <- matrix(0, nrow=nrow_f2, ncol=ncol_f2)
  
  copia_2[i, ] <- wavelets::idwt(copia[[i]])
  }
  return(copia_2)
}
```

Tomamos una imagen a color, realizamos transformadas wavelet a sus filas y reconstruimos la imagen habiendo eliminado los niveles de detalle
```{r 2_1_2_ejemplo_1_1, echo=FALSE}
matriz_imagen <- perro_01

copia_dwt_filas_color <- extraccion_wavelet_filas(matriz_imagen, filtro_wavelet="haar")
```

```{r 2_1_2_ejemplo_1_2, echo=FALSE}
matriz_ceros <- matrix(0, nrow=dim(matriz_imagen)[1], ncol=dim(matriz_imagen)[2])

# Asignamos a una variable cada uno de los tres canales, porque la función filtro_filas_paso_bajo_color trabaja sobre los canales individualmente, no sobre la matriz.
copia_rojo <- copia_dwt_filas_color$wavelet_filas_R
copia_verde <- copia_dwt_filas_color$wavelet_filas_G
copia_azul <- copia_dwt_filas_color$wavelet_filas_B

copia_filas_rojo <- filtro_filas_paso_bajo_color(copia_rojo, matriz_ceros)
copia_filas_verde <- filtro_filas_paso_bajo_color(copia_verde, matriz_ceros)
copia_filas_azul <- filtro_filas_paso_bajo_color(copia_azul, matriz_ceros)

grid.newpage()
grid.raster(perro_01/255)

dimensiones <- c(dim(copia_filas_rojo), 3) # Las dimensiones de la matriz imagen aproximada (mismas filas y columnas que cualquiera de los tres canales [en este caso hemos tomado el rojo] y una profundidad de 3 [rojo, verde y azul])

# Las sigientes filas muestran las aproximaciones de la imagen original en los tres colores (rojo, verde y azul), están comentadas para que el documento final no se llene de imágenes

# dim_rojo <- dimensiones
# matriz_filas_rojo <- array(0, dim = dim_rojo)
# matriz_filas_rojo[ , , 1] <- copia_filas_rojo
# grid.newpage()
# grid.raster(matriz_filas_rojo/255)
# 
# dim_verde <- c(dim(copia_filas_verde), 3)
# matriz_filas_verde <- array(0, dim = dim_verde)
# matriz_filas_verde[ , , 2] <- copia_filas_verde
# grid.newpage()
# grid.raster(matriz_filas_verde/255)
# 
# dim_azul <- c(dim(copia_filas_azul), 3)
# matriz_filas_azul <- array(0, dim = dim_azul)
# matriz_filas_azul[ , , 3] <- copia_filas_azul
# grid.newpage()
# grid.raster(matriz_filas_azul/255)

# Creamos una matriz de ceros con el tamaño de la matriz imagen aproximada y asignamos los tres canales de colores a sendas profundidades
matriz_filas_colores <- array(0, dim = dimensiones)
matriz_filas_colores[ , , 1] <- copia_filas_rojo
matriz_filas_colores[ , , 2] <- copia_filas_verde
matriz_filas_colores[ , , 3] <- copia_filas_azul

grid.newpage()
grid.raster(matriz_filas_colores/255) # Dado que la matriz matriz_filas_colores/255 tiene una profundidad de 3, la función grid.raster interpreta que está en RGB.
```


### b. Reconstrucción de imagen para la transformada wavelet concatenando todas las filas de la matriz.

Realizamos el algoritmo que concatena todas las filas de la matriz y, por tanto, realiza una única transformada wavelet
```{r 2_2_1_concatenar, echo=FALSE}
comp_concatenada_filas <- function(matriz_imagen, filtro="haar", niveles=2){
  copia_concatenada <- matriz_imagen
  copia_concatenada <- as.numeric(t(copia_concatenada)) # Concatenamos todos los elementos de la matriz en una única fila (trasponemos la matriz porque R ordena los elementos por columnas en vez de por filas)
  
  copia_concatenada_dwt <- wavelets::dwt(copia_concatenada, filter = filtro, n.levels=niveles)

  nrow_f1 <- dim(copia_concatenada_dwt@W$W1)[1]
  ncol_f1 <- dim(copia_concatenada_dwt@W$W1)[2]
  
  nrow_f2 <- dim(copia_concatenada_dwt@W$W2)[1]
  ncol_f2 <- dim(copia_concatenada_dwt@W$W2)[2]
  
  copia_concatenada_dwt@W$W1 <- matrix(0, nrow=nrow_f1, ncol=ncol_f1)
  copia_concatenada_dwt@W$W2 <- matrix(0, nrow=nrow_f2, ncol=ncol_f2)
  
  copia_concatenada_2 <- wavelets::idwt(copia_concatenada_dwt)
  
  # Deshacemos el cambio de dimensiones para volver a tener una matriz con las dimensiones que poseía al inicio 
  copia_concatenada_2 <- matrix(copia_concatenada_2, nrow=dim(matriz_imagen)[1],
                                ncol=dim(matriz_imagen)[2], byrow=TRUE)
  
  return(copia_concatenada_2)
}

comp_concatenada_filas_RGB <- function(matriz_imagen, filtro="haar", niveles=2){
  R_channel <- comp_concatenada_filas(matriz_imagen[,,1], filtro = filtro, niveles = niveles) 
  B_channel <- comp_concatenada_filas(matriz_imagen[,,2], filtro = filtro, niveles = niveles) 
  G_channel <- comp_concatenada_filas(matriz_imagen[,,3], filtro = filtro, niveles = niveles)
  
  matrix_RGB <-  array(0, dim= c( nrow(R_channel) , ncol(R_channel), 3 )  )
  matrix_RGB[,,1]<- R_channel
  matrix_RGB[,,2]<- B_channel
  matrix_RGB[,,3]<- G_channel

  return(matrix_RGB)
}
```


Aplicamos el algoritmo a los tres canales de color de nuestra imagen
```{r 2_2_2_aplicar_a_concatenar, echo=FALSE}

grid.newpage()
grid.raster(perro_01/255)

dimensiones <- c(dim(copia_filas_rojo), 3)

matriz_concatenada_colores <- comp_concatenada_filas_RGB( perro_01 )

grid.newpage()
grid.raster(matriz_concatenada_colores/255)
```

```{r 2_2_2_aplicar_a_concatenar_correccion, echo=FALSE}
matriz_imagen <- perro_01

matriz_concatenada_rojo <- comp_concatenada_filas(perro_01[,,1])
matriz_concatenada_verde <- comp_concatenada_filas(perro_01[,,2])
matriz_concatenada_azul <- comp_concatenada_filas(perro_01[,,3])


grid.newpage()
grid.raster(perro_01/255)

dimensiones <- c(dim(copia_filas_rojo), 3)

matriz_concatenada_colores <- array(0, dim = dimensiones)
matriz_concatenada_colores[ , , 1] <- matriz_concatenada_rojo
matriz_concatenada_colores[ , , 2] <- matriz_concatenada_verde
matriz_concatenada_colores[ , , 3] <- matriz_concatenada_azul

grid.newpage()
grid.raster(matriz_concatenada_colores/255)
```

Destacamos que la imagen obtenida al realizar transformadas wavelet iterativamente a las filas de la matriz nos devuelve exactamente el mismo resultado que si concatenamos todas las filas de la matriz y realizamos una única transformada wavelet.
Esto lo podemos ver confirmado con la función `identical`
```{r 2_2_3_son_iguales, echo=FALSE}
identical(matriz_filas_colores, matriz_concatenada_colores)
```

## 3.2. Algoritmos de compresión bidimensionales.

### a. Generar algoritmos de reconstrucción de imagen a partir de los coeficientes wavelets.

La siguiente función (`filtro2d_paso_bajo`) realiza un filtro de paso bajo sobre los coeficientes de la transformada wavelet discreta en 2D. Esta función elimina las componentes de alta frecuencia (LH1, HL1, HH1) de la imagen, dejando todos los coeficientes de estas componentes en cero para reducir la información. Notamos que este filtro elimina el $75$% de los coeficientes de la transformada wavelet.

```{r 3_2_filtro_paso_bajo_2D_1, echo = TRUE}
filtro2d_paso_bajo <- function(dwt2d_imag) {
  dim <- dim(dwt2d_imag$LH1)
  
  dwt2d_imag$LH1 <- matrix(0, nrow = dim[1], ncol = dim[2])
  dwt2d_imag$HL1 <- matrix(0, nrow = dim[1], ncol = dim[2])
  dwt2d_imag$HH1 <- matrix(0, nrow = dim[1], ncol = dim[2])
  
  return(dwt2d_imag)
}
```

La siguiente función (`filtro2d_paso_bajo2`) realiza un filtro de paso bajo sobre los coeficientes de la transformada wavelet discreta en 2D ajustado por un umbral. Esta función elimina los coeficientes de las componentes de alta frecuencia (LH1, HL1, HH1) de la imagen, dejándolos en cero, si son menores o iguales que el umbral `q` (que es el cuantil elegido de los coeficientes, en valor absoluto, de la subbanda de la imagen respectiva) para reducir la información. Notamos que este filtro elimina el ($q*75$)% de los coeficientes de la transformada wavelet. La función anterior es el caso particular $q = 1$ de esta función.

```{r 3_2_filtro_paso_bajo_2D_2, echo = TRUE}
filtro2d_paso_bajo2 <- function(dwt2d_imag, q) {
  dwt2d_imag$LH1 <- ifelse(abs(dwt2d_imag$LH1) <= quantile(abs(dwt2d_imag$LH1), q), 0, dwt2d_imag$LH1)
  dwt2d_imag$HL1 <- ifelse(abs(dwt2d_imag$HL1) <= quantile(abs(dwt2d_imag$HL1), q), 0, dwt2d_imag$HL1)
  dwt2d_imag$HH1 <- ifelse(abs(dwt2d_imag$HH1) <= quantile(abs(dwt2d_imag$HH1), q), 0, dwt2d_imag$HH1)
  
  return(dwt2d_imag)
}
```

La siguiente función (`aplic_dwt`) aplica la transformada wavelet discreta en 2D a la imagen si está en blanco y negro (`bn == TRUE`), o se aplica a los tres canales de la imagen si no está en blanco y negro (`bn == FALSE`), especificado el tipo de wavelet madre (`wf`) y el nivel.

```{r 3_2_aplicar_DWT_2D, echo = TRUE}
aplic_dwt <- function(imag, bn, wf, nivel) {
  if (bn) {
    dwt_imagen <- dwt.2d(imag, wf = wf, J = nivel)
    return(dwt_imagen)
  } else {
    dwt_imagen_r <- dwt.2d(imag[,,1], wf = wf, J = nivel)
    dwt_imagen_g <- dwt.2d(imag[,,2], wf = wf, J = nivel)
    dwt_imagen_b <- dwt.2d(imag[,,3], wf = wf, J = nivel)
    return(list(dwt_imagen_r, dwt_imagen_g, dwt_imagen_b))
  }
}
```

La siguiente función (`filtrar_dwt`) aplica el filtro a la imagen dada su transformada wavelet discreta en 2D si está en blanco y negro (`bn == TRUE`), o dadas las transformadas wavelet de sus tres canales si no está en blanco y negro (`bn == FALSE`); y especificado el filtro a usar: si `filtroQ == FALSE`, se usa el filtro `filtro2d_paso_bajo`, y si `filtroQ == TRUE`, se usa el filtro `filtro2d_paso_bajo2`. En este último caso, también se deberá especificar el cuantil (`q`) que se quiera usar en el filtro.

```{r 3_2_filtrar_DWT_2D, echo = TRUE}
filtrar_dwt <- function(dwt_imagen, bn = FALSE, filtroQ = FALSE, q = -1) {
  if (bn) {
    if (!(filtroQ)) {
      dwt_imag_filt <- filtro2d_paso_bajo(dwt_imagen)
      return(dwt_imag_filt)
    } else {
      dwt_imag_filt <- filtro2d_paso_bajo2(dwt_imagen, q)
      return(dwt_imag_filt)
    }
  } else {
    if (!(filtroQ)) {
      dwt_imag_filt_r <- filtro2d_paso_bajo(dwt_imagen[[1]])
      dwt_imag_filt_g <- filtro2d_paso_bajo(dwt_imagen[[2]])
      dwt_imag_filt_b <- filtro2d_paso_bajo(dwt_imagen[[3]])
      return(list(dwt_imag_filt_r, dwt_imag_filt_g, dwt_imag_filt_b))
    } else {
      dwt_imag_filt_r <- filtro2d_paso_bajo2(dwt_imagen[[1]], q)
      dwt_imag_filt_g <- filtro2d_paso_bajo2(dwt_imagen[[2]], q)
      dwt_imag_filt_b <- filtro2d_paso_bajo2(dwt_imagen[[3]], q)
      return(list(dwt_imag_filt_r, dwt_imag_filt_g, dwt_imag_filt_b))
    }
  }
}
```

La función `reconstruir_imag` reconstruye la imagen dada su dimensión, y dada su transformada wavelet discreta 2D si la imagen está en blanco y negro (`bn == TRUE`), o dadas las transformadas wavelet discretas en 2D de sus tres canales si la imagen no está en blanco y negro (`bn == FALSE`).

```{r 3_2_reconstruir_imag, echo = TRUE}
reconstruir_imag <- function(dwt_imagen, bn, dim) {
  if (bn) {
    imagen_rec <- idwt.2d(dwt_imagen)
    return(imagen_rec)
  } else {
    imagen_rec_rgb <- array(0, dim = c(dim[1], dim[2], 3))
    imagen_rec_rgb[,,1] <- idwt.2d(dwt_imagen[[1]])
    imagen_rec_rgb[,,2] <- idwt.2d(dwt_imagen[[2]])
    imagen_rec_rgb[,,3] <- idwt.2d(dwt_imagen[[3]])
    return(imagen_rec_rgb)
  }
}
```

Procedemos a comprimir la imagen usada en el apartado anterior utilizando los dos filtros que actúan sobre la transformada wavelet discreta en 2D de la imagen. El segundo filtro se probará para varios cuantiles (0.5, 0.7 y 0.9).

```{r 3_1_2_ejemplo_1_1, echo=FALSE}
matriz_imagen <- perro_01
dim <- dim(matriz_imagen)

dwt_imagen <- aplic_dwt(matriz_imagen, FALSE, "haar", 1)
imagen_comp1 <- filtrar_dwt(dwt_imagen, FALSE)
imagen_rec1 <- reconstruir_imag(imagen_comp1, FALSE, dim)
q <- c(0.5, 0.7, 0.9)
imagen_comp21 <- filtrar_dwt(dwt_imagen, FALSE, TRUE, q[1])
imagen_rec21 <- reconstruir_imag(imagen_comp21, FALSE, dim)
imagen_comp22 <- filtrar_dwt(dwt_imagen, FALSE, TRUE, q[2])
imagen_rec22 <- reconstruir_imag(imagen_comp22, FALSE, dim)
imagen_comp23 <- filtrar_dwt(dwt_imagen, FALSE, TRUE, q[3])
imagen_rec23 <- reconstruir_imag(imagen_comp23, FALSE, dim)
```

Asimismo, procedemos a mostrar la imagen comprimida con el filtro de paso bajo, y las imágenes comprimidas con el filtro de paso bajo utilizando el umbral.

Imagen comprimida usando el primer filtro:

```{r 3_1_2_ejemplo_1, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec1 / 255)
```

Imagen comprimida usando el segundo filtro con `q = 0.5`:

```{r 3_1_2_ejemplo_2, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec21 / 255)
```

Imagen comprimida usando el segundo filtro con `q = 0.7`:

```{r 3_1_2_ejemplo_3, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec22 / 255)
```

Imagen comprimida usando el segundo filtro con `q = 0.9`:

```{r 3_1_2_ejemplo_4, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec23 / 255)
```

### b. Programar (o buscar) funciones (por ejemplo MSE) para medir el error entre la imagen original y la comprimida.

MSE: Error Cuadrático Medio. Media aritmética de los MSEs de los tres canales.

```{r 3_2_1_medidas_de_error_MSE, echo=TRUE}
mse_imags <- function(imag1, imag2, bn = FALSE) {
  if (bn) {
    return(mean((imag1 - imag2)^2))
  } else {
    return(mean(c(mean((imag1[,,1] - imag2[,,1])^2), mean((imag1[,,2] - imag2[,,2])^2), mean((imag1[,,3] - imag2[,,3])^2))))
  }
}
```

MAE: Error Absoluto Medio. Media aritmética de los MAEs de los tres canales.

```{r 3_2_1_medidas_de_error_MAE, echo=TRUE}
mae_imags <- function(imag1, imag2, bn = FALSE) {
  if (bn) {
    return(mean(abs(imag1 - imag2)))
  } else {
    return(mean(c(mean(abs(imag1[,,1] - imag2[,,1])), mean(abs(imag1[,,2] - imag2[,,2])), mean(abs(imag1[,,3] - imag2[,,3])))))
  }
}
```

PSNR: Proporción Máxima de Señal-Ruido (relación entre la máxima energía posible de una señal y el ruido que afecta a su representación fidedigna). El MSE se ha calculado como la media aritmética de los MSEs de los tres canales.

```{r 3_2_1_medidas_de_error_PSNR, echo=TRUE}
psnr_imags <- function(imag1, imag2, bn = FALSE) {
  mse <- mse_imags(imag1, imag2, bn)
  max_intensidad <- 255
  return(10 * log10((max_intensidad^2) / mse))
}
```

La siguiente función (`calc_errores`) calcula los errores MSE y MAE, y el PSNR entre `imag1` e `imag2`, especificado si ambas imágenes están en blanco y negro (`bn = TRUE`), o no.

```{r 3_2_1_medidas_de_error_calcular_errores, echo=TRUE}
calc_errores <- function(imag1, imag2, bn = FALSE) {
  return(c("MSE" = mse_imags(imag1, imag2, bn), "MAE" = mae_imags(imag1, imag2, bn), "PSNR" = psnr_imags(imag1, imag2, bn)))
}
```

### c. Analizar y ordenar los algoritmos vistos hasta el momento en base a la relación calidad / nivel de compresión

Procedemos a calcular los errores MSE y MAE, y el PSNR entre la imagen original y las imágenes comprimidas.

```{r 3_3_1_errores_en_ejemplo_3_1, echo=FALSE}
print("Error filtro paso bajo:")
calc_errores(matriz_imagen, imagen_rec1)
print("Error filtro paso bajo 2, q = 0.5:")
calc_errores(matriz_imagen, imagen_rec21)
print("Error filtro paso bajo 2, q = 0.7:")
calc_errores(matriz_imagen, imagen_rec22)
print("Error filtro paso bajo 2, q = 0.9:")
calc_errores(matriz_imagen, imagen_rec23)
print("Error filtro paso bajo por filas:")
calc_errores(matriz_imagen, matriz_filas_colores)
```

Tras obtener los resultados, notamos que la compresión que usa el filtro de paso bajo con el umbral aplicado a la transformada wavelet discreta en 2D es el que proporciona la mayor calidad de imagen (cuanto menor sea el cuantil, más calidad se conserva), seguido de la compresión que usa el filtro de paso bajo aplicado a la transformada wavelet discreta en 2D.

Ahora, se procede a generar una tabla que contiene información sobre el MSE, MAE y PSNR entre cada imagen en color y su respectiva imagen comprimida obtenida con el método 1 (usando el filtro `filtro2d_paso_bajo`) o con el método 2 (usando el filtro `filtro2d_paso_bajo2` y eligiendo el cuantil 0.7).

```{r 3_3_2_tabla_errores_imagenesRGB, echo=FALSE}
imags <- list(arbol_01, arbol_03, perro_01, flor_01, flor_02, planta_01, pinas_01, gato_01)
nombres <- c("arbol_01", "arbol_03", "perro_01", "flor_01", "flor_02", "planta_01", "pinas_01", "gato_01")
cols <- c("Imagen", "Método", "MSE", "MAE", "PSNR")
tabla_info <- data.frame(matrix(ncol = length(cols), nrow = 0))
q <- 0.7

for (i in 1:length(imags)) {
  imag <- imags[[i]]
  dim <- dim(imag)
  
  dwt_imagen <- aplic_dwt(imag, FALSE, "haar", 1)
  imagen_comp1 <- filtrar_dwt(dwt_imagen, FALSE)
  imagen_rec1 <- reconstruir_imag(imagen_comp1, FALSE, dim)
  
  imagen_comp2 <- filtrar_dwt(dwt_imagen, FALSE, TRUE, q)
  imagen_rec2 <- reconstruir_imag(imagen_comp2, FALSE, dim)
  
  info1 <- calc_errores(imag, imagen_rec1)
  info2 <- calc_errores(imag, imagen_rec2)
  nom_info1 <- c(c(nombres[i], "Método 1"), info1)
  nom_info2 <- c(c(nombres[i], "Método 2"), info2)
  tabla_info <- rbind(tabla_info, nom_info1)
  tabla_info <- rbind(tabla_info, nom_info2)
}

colnames(tabla_info) <- cols
```

```{r 3_3_3_ver_tabla_errores_imagenesRGB, echo=FALSE}
print(tabla_info)
```

A continuación, procedemos a comprimir una imagen en blanco y negro utilizando los dos filtros que actúan sobre la transformada wavelet discreta en 2D de la imagen. El segundo filtro se probará para varios cuantiles (0.5, 0.7 y 0.9).

```{r 3_3_4_ejemplo_bn, echo=FALSE}
matriz_imagen <- gato_02_filtro
dim <- dim(matriz_imagen)

dwt_imagen <- aplic_dwt(matriz_imagen, TRUE, "haar", 1)
imagen_comp1 <- filtrar_dwt(dwt_imagen, TRUE)
imagen_rec1 <- reconstruir_imag(imagen_comp1, TRUE, dim)
q <- c(0.5, 0.7, 0.9)
imagen_comp21 <- filtrar_dwt(dwt_imagen, TRUE, TRUE, q[1])
imagen_rec21 <- reconstruir_imag(imagen_comp21, TRUE, dim)
imagen_comp22 <- filtrar_dwt(dwt_imagen, TRUE, TRUE, q[2])
imagen_rec22 <- reconstruir_imag(imagen_comp22, TRUE, dim)
imagen_comp23 <- filtrar_dwt(dwt_imagen, TRUE, TRUE, q[3])
imagen_rec23 <- reconstruir_imag(imagen_comp23, TRUE, dim)
```

Asimismo, procedemos a mostrar la imagen comprimida con el filtro de paso bajo, y las imágenes comprimidas con el filtro de paso bajo utilizando el umbral.

Imagen comprimida usando el primer filtro:

```{r 3_3_5_ejemplo_bn_1, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec1 / 255)
```

Imagen comprimida usando el segundo filtro con `q = 0.5`:

```{r 3_3_5_ejemplo_bn_2, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec21 / 255)
```

Imagen comprimida usando el segundo filtro con `q = 0.7`:

```{r 3_3_5_ejemplo_bn_3, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec22 / 255)
```

Imagen comprimida usando el segundo filtro con `q = 0.9`:

```{r 3_3_5_ejemplo_bn_4, echo=FALSE}
grid.newpage()
grid.raster(imagen_rec23 / 255)
```

Procedemos a calcular los errores MSE y MAE, y el PSNR entre la imagen original y las imágenes comprimidas.

```{r 3_3_6_errores_ejemplo_bn, echo=FALSE}
print("Error filtro paso bajo:")
calc_errores(matriz_imagen, imagen_rec1, TRUE)
print("Error filtro paso bajo 2, q = 0.5:")
calc_errores(matriz_imagen, imagen_rec21, TRUE)
print("Error filtro paso bajo 2, q = 0.7:")
calc_errores(matriz_imagen, imagen_rec22, TRUE)
print("Error filtro paso bajo 2, q = 0.9:")
calc_errores(matriz_imagen, imagen_rec23, TRUE)
```

Ahora, se procede a generar una tabla que contiene información sobre el MSE, MAE y PSNR entre cada imagen en blanco y negro y su respectiva imagen comprimida con el método 1 (usando el filtro `filtro2d_paso_bajo`) o con el método 2 (usando el filtro `filtro2d_paso_bajo2` y eligiendo el cuantil 0.7).

```{r 3_3_2_tabla_errores_imagenesBN, echo=FALSE}
imags <- list(flor_04_filtro, flor_05_filtro, peluche_01_filtro, gato_02_filtro)
nombres <- c("flor_04_filtro", "flor_05_filtro", "peluche_01_filtro", "gato_02_filtro")
cols <- c("Imagen", "Método", "MSE", "MAE", "PSNR")
tabla_info2 <- data.frame(matrix(ncol = length(cols), nrow = 0))
q <- 0.7

for (i in 1:length(imags)) {
  imag <- imags[[i]]
  dim <- dim(imag)
  
  dwt_imagen <- aplic_dwt(imag, TRUE, "haar", 1)
  imagen_comp1 <- filtrar_dwt(dwt_imagen, TRUE)
  imagen_rec1 <- reconstruir_imag(imagen_comp1, TRUE, dim)
  
  imagen_comp2 <- filtrar_dwt(dwt_imagen, TRUE, TRUE, q)
  imagen_rec2 <- reconstruir_imag(imagen_comp2, TRUE, dim)
  
  info1 <- calc_errores(imag, imagen_rec1, TRUE)
  info2 <- calc_errores(imag, imagen_rec2, TRUE)
  nom_info1 <- c(c(nombres[i], "Método 1"), info1)
  nom_info2 <- c(c(nombres[i], "Método 2"), info2)
  tabla_info2 <- rbind(tabla_info2, nom_info1)
  tabla_info2 <- rbind(tabla_info2, nom_info2)
}

colnames(tabla_info2) <- cols
```

```{r 3_3_2_ver_tabla_errores_imagenesBN, echo=FALSE}
print(tabla_info2)
```


# 5. Importación de vídeos y preacondicionamiento

Para esta nueva sección se prueba a emplear la transformada wavelet a vídeos. En general, un vídeo se compone de una sucesión de fotogramas (imágenes) que se reproducen a una velocidad determinada. Por ello, simplemente implica realizar el trabajo realizado en los apartados anteriores para cada fotograma del vídeo.

En esta primera sección se encarga de importar los vídeos, extraer los fotogramas según los fps indicados, transformarlos en matrices RGB y reescalar la matriz a una cuadrada para posteriomente poder aplicar la funció wavelet.

### a. Importación de video

```{r 5_1_1_importar_fichero_videos, echo=FALSE}
# Directorio objetivo
video_dir <- "videos"

# Listar archivos 
video_files <- list.files(video_dir, pattern = "\\.mp4$", full.names = TRUE)

# Mostrar nombres de los vídeos encontrados
if (length(video_files) == 0) {
  print("No se encontraron vídeos en el directorio.")
} else {
  print("Se encontraron los siguientes vídeos:")
  print(video_files)
}

# Selección de video a procesar (en este caso el 1º)
#video_path <- video_files[1]
```

```{r 5_1_2_fun_extraccion_fotogramas, echo=FALSE}
# Extraer fotogramas
extract_frames <- function(video_path, fps = 1) { #Manejar FPs con cuidado. Si se escala a un valor muy alto, se pueden generar demasiados fotogramas y saturar la memoria.
  # Extraer fotogramas como raw binary
  frames_raw <- invisible(av::av_video_images(video = video_path, format = "png", fps = fps))
  
  # Convertir raw binary a imágenes magick
  frames <- lapply(frames_raw, magick::image_read)
  frames
}
```

Primero se emplea la función (`extract_frames`) que se encarga de extraer los fotogramas de un vídeo a partir de un "path" y la tasa de fotogramas de captura usando la librería "av". A partir del parámetro de fps, el algoritmo extrae la misma cantidad de fotogramas por segundo. Como resultado, devuelve la lista con los fotogramas extraídos ordenados.  

```{r 5_1_3_extraccion_fotogramas, echo=FALSE}
# Extraer fotogramas de cada video del fichero
videoframes_list <- c()
for (i in video_files){
  frames <- extract_frames(i)

  # Mostrar número de fotogramas extraídos
  cat("Se extrajeron", length(frames), "fotogramas del vídeo.\n")

  #Añadir a lista de fotogramas
  videoframes_list <- c(videoframes_list, list(frames))
  }
```
Como resultado se observa los fotogramas extraídos en dos vídeos diferentes. Para el primer vídeo de 13 segundos, se extraen un total de 13 fotogramas con un parámetro de 1 asignado a fps. Para el segundo, se observa un total de 8 fotogramas extraídos para una duración de 8 segundos.

```{r 5_1_3_1_visualizacion_fotogramas_extraidos, echo=FALSE}
# Visualizar fotogramas extraídos para un video específico

  grobs <- lapply(videoframes_list[[1]], grid::rasterGrob)
  grid.arrange(grobs = grobs, nrow = 4, ncol = 4)
```
Este es un ejemplo de los fotogramas extraídos para el primer video, con un total de 13.

### b.  Transformar vídeos a matrices RGB: (Width X Height X 3 X #Fotogramas )

```{r 5_2_1_fun_frames_a_matrices, echo=FALSE}
# Convertir imágenes en memoria a matrices RGB
convert_frames_to_rgb <- function(frames) {
  rgb_matrices <- lapply(frames, function(img) {
    
    # Convertir la imagen a un array de píxeles
    img_array <- as.integer(image_data(img))
    
    # Obtener las dimensiones del array
    dims <- dim(img_array)
    
    # Verificar que la imagen tiene 3 canales
    if (length(dims) != 3 || dims[3] != 3) {
      stop("La imagen debe ser RGB con exactamente 3 canales (R, G, B).")
    }
    rgb_matrix <- img_array
    return(rgb_matrix)
    })
  rgb_matrices
}


```

La siguiente función (`convert_frames_to_rgb`) cumple la simple función de transformar las imágenes a matrices convencionales RGB. Para ello, se convierte la imagen a un array de píxeles y se obtienen las dimensiones del array. Posteriormente, se verifica que la imagen tenga 3 canales (R, G, B) y se devuelve la matriz RGB.

```{r 5_2_2_frames_a_matrices, echo=FALSE}
#Convertir fotogramas de la lista a matrices RGB

rgb_matrices_list <- c()

for (i in videoframes_list){
  rgb_matrices_list <- c(rgb_matrices_list, list(convert_frames_to_rgb(i)))
}
```

### c.  Normalizar las matrices RGB 

```{r 5_3_1_fun_redimensionar_matrices, echo=FALSE}
normalize_matrices <- function(rgb_matrices, target_width = 256, target_height = 256) {
  # Verificar que la librería 'magick' está cargada
  if (!requireNamespace("magick", quietly = TRUE)) {
    stop("El paquete 'magick' es necesario. Instálalo con install.packages('magick').")
  }
  
  # Normalizar cada matriz RGB
  normalized_matrices <- lapply(rgb_matrices, function(matrix) {
    # Verificar que la matriz es una matriz RGB válida
    if (length(dim(matrix)) != 3 || dim(matrix)[3] != 3) {
      stop("Cada elemento de 'rgb_matrices' debe ser una matriz tridimensional con la última dimensión igual a 3 (R, G, B).")
    }
    
    # Convertir la matriz a un objeto magick
    if (max(matrix) <= 1) {
      # Escalar a rango 0-255 si los valores están en 0-1
      matrix <- matrix * 255
    }
    img <- magick::image_read(as.raster(matrix / 255)) # Crear imagen magick
    
    # Redimensionar la imagen al tamaño objetivo
    resized_img <- magick::image_resize(img, paste0(target_width, "x", target_height, "!"))
    
    # Convertir de nuevo la imagen a una matriz RGB normalizada en rango [0, 1]
    resized_matrix <- as.integer(magick::image_data(resized_img)) / 255
    
    # Eliminar el canal alfa si existe (reduciendo la matriz a 3 canales: R, G, B)
    if (dim(resized_matrix)[3] == 4) {
      resized_matrix <- resized_matrix[, , 1:3]
    }
    
    return(resized_matrix)
  })
  
  return(normalized_matrices)
}
```

Siguiendo con la función (`normalize_matrices`). Se encarga de normalizar las matrices RGB a un tamaño objetivo. Para ello, se verifica que la matriz sea una matriz RGB válida, se convierte la matriz a un objeto magick, se redimensiona la imagen al tamaño objetivo, se convierte de nuevo la imagen a una matriz RGB normalizada en rango [0, 1] y se elimina el canal alfa si existe (reduciendo la matriz a 3 canales: R, G, B). Esto asegura que la matriz sea cuadrada, una de las condiciones necesarias para poder aplicar la función wavelet.

```{r 5_3_2_normalizar_matrices, echo=FALSE}

normalized_matrices_list <- c()

for (i in rgb_matrices_list){
  normalized_matrices_list <- c(normalized_matrices_list, list(normalize_matrices(i)))
}

# Mostrar dimensiones normalizadas
cat("Dimensiones normalizadas de un fotograma:\n")
print(dim(normalized_matrices_list[[1]][[1]]))

```

```{r 5_3_4_visualizar_matrices_RGB, echo=FALSE}
visualizar_imagen_RGB <- function(matriz_RGB) {
  # Verificar que la matriz tiene tres dimensiones con la última dimensión de tamaño 3
  if (length(dim(matriz_RGB)) != 3 || dim(matriz_RGB)[3] != 3) {
      stop("La matriz debe tener tres dimensiones con la última dimensión de tamaño 3 (R, G, B).")
  }
  
  # Asegurarse de que los valores están en el rango [0, 1]
  if (max(matriz_RGB) > 1 || min(matriz_RGB) < 0) {
    warning("Los valores de la matriz RGB no están en el rango [0, 1]. Normalizando automáticamente.")
    matriz_RGB <- matriz_RGB / max(matriz_RGB)
  }
  
  # Convertir la matriz a un objeto de imagen magick
  img <- magick::image_read(as.raster(matriz_RGB))
  
  # Mostrar la imagen
  #print(img)
  grid.newpage()
  grid.raster(img)
}

visualizar_imagen_RGB(normalized_matrices_list[[1]][[1]])
```


Esta última función (`visualizar_imagen_RGB`) se encarga de dar una última comprobación de requisitos para la matriz RBG y representa la imagen una vez ya redimensionada para comprobar que todo ha sido correcto.

Con esta última finalización se termina el proceso de carga y preacondicionado de los vídeos. Se ha conseguido extraer los fotogramas de los vídeos, transformarlos en matrices RGB y reescalar las matrices a una cuadrada para poder aplicar la función wavelet en los posteriores apartados.

# 6. Aplicación de Transformadas wavelet:

```{r 5_1_1_transformada_wavelet_2d_por_fotograma }

aplic_dwt2d_video <- function(video_frames, bn, wf, nivel){
  dwt_frames <- c()
  for (i in 1:length(video_frames)){
    dwt_frames <- c(dwt_frames, list( aplic_dwt( imag = video_frames[[i]] ,bn=bn,wf=wf,nivel=nivel)) )
  }
  return(dwt_frames)
}

aplic_dwt_concat_video <- function(video_frames, bn, filtro, nivel){
  dwt_frames <- c()
  for (i in 1:length(video_frames)){
    dwt_frames <- c(dwt_frames, list( aplicar_dwt_vector( imag = video_frames[[i]] ,bn=bn,filtro,nivel=nivel)) )
  }
  return(dwt_frames)
}
  
dwt2d_videos <- c()
dwt_concat_videos<- c()

for (i in 1:length(normalized_matrices_list)){  #Iteramos sobre cada video
    dwt2d_videos<- c(dwt2d_videos, list( aplic_dwt2d_video( normalized_matrices_list[[i]], bn=FALSE, wf = "haar", nivel=2) ) )
    dwt_concat_videos<- c(dwt_concat_videos, list( aplic_dwt_concat_video( normalized_matrices_list[[i]], bn=FALSE, filtro = "haar", nivel=2) ) )
}
```

La variable dwt2d_videos es una lista que contiene:

  - Una lista por cada vídeo que contiene     (dwt2d_videos[[video_i]]):
  - Una lista por cada fotograma del vídeo que contiene (dwt2d_videos[[video_i]][[fotograma_j]]):
  - La transformada wavelet del canal R [[1]], G [[2]] o B [[3]]

La estructura de la variable dwt_concat_videos es similar a la anterior:

  - Una lista por cada vídeo que contiene     (dwt_concat_videos[[video_i]]):
  - Una lista por cada fotograma del vídeo que contiene (dwt_concat_videos[[video_i]][[fotograma_j]]):
  - La transformada wavelet del canal R [[1]], G [[2]] o B [[3]]

Una cosa que puede ser especialmente útil para algoritmos de compresión aplicados a vídeos más o menos "estáticos", es decir, vídeos dónde un porcentaje elevado de píxeles no varía o varía muy poco, es aplicar la compresión al vector transición entre dos fotogramas, en vez de al fotograma en sí.

Concretamente, el algoritmo reconstruiría el vídeo a partir del primer fotograma (comprimido) y de los vectores transición (también comprimidos). 
Con este objetivo preparamos el cálculo de la transformada wavelet de las transiciones.

```{r 5_1_4_transformada_wavelet_2d_y_concat_transicion, echo=FALSE }
dwt_trans_2d_videos <- c()
dwt_trans_concat_videos <- c()

for (j in 1:length(normalized_matrices_list)){  #Iteramos sobre cada video
    
    aux_trans <-  list( normalized_matrices_list[[j]][[1]] )
    for (i in 1:(length(videoframes_list[[j]]) -1 )){
      aux_trans <- c( aux_trans , list( normalized_matrices_list[[j]][[i+1]] - normalized_matrices_list[[j]][[i]] )  )
    }
    dwt_trans_2d_videos<- c(dwt_trans_2d_videos, list( aplic_dwt2d_video( aux_trans, bn=FALSE, wf = "haar", nivel=2) ) )
    dwt_trans_concat_videos<- c(dwt_trans_concat_videos, list( aplic_dwt_concat_video( aux_trans, bn=FALSE, filtro = "haar", nivel=2) ) )
}
```

Ahora las variables dwt_trans_2d_videos y dwt_trans_concat_videos guardan:

  - Una lista por cada vídeo que contiene     (dwt_concat_videos[[  video_files[i]  ]]):
  - Una lista con longitud el número de fotogramas del vídeo que contiene (dwt_concat_videos[[video_i]][[j]]):
    - Si j=1: La transformada wavelet del canal R [[1]], G [[2]] o B [[3]] del fotograma 1
    - Si j>1: La transformada wavelet del canal R [[1]], G [[2]] o B [[3]] del vector transición del fotograma j-1 al j

# 7. Algoritmos de compresión:

Con los coeficientes wavelets obtenidos, seríamos capaces de reconstruir los vídeo originales. Sin embargo, también podemos modificar dichos coeficientes aplicando filtros y transformaciones para reducir la información que contienen sin alterar mucho la integridad del vídeo. De esta manera, habremos comprimido el vídeo.

Una de las maneras más fáciles de comprimir y reconstruir estos vídeos, sería aplicando el proceso de compresión y reconstrucción por coeficientes wavelets visto en el apartado 3 a cada fotograma del vídeo. Si bien este método es funcional, no utiliza en ningún momento las propiedades de los vídeos, y reduce estos a imágenes independientes.

Así, si queremos crear métodos de reconstrucción y compresión realmente interesantes, debemos aprovechar las propiedades de los vídeos como fotogramas consecutivos.

### a. Generar algoritmos de reconstrucción de vídeo a partir de los coeficientes wavelets.

En nuestros algoritmos, aplicaremos tres posibles distintas compresiones:

* Ninguna compresión.
* Compresión a través del filtro de paso bajo del apartado 3.2.
* Compresión a través del segundo filtro de paso bajo del apartado 3.2.

Además, estas compresiones y reconstrucciones se utilizaran de dos maneras distintas.

* Fotograma a fotograma por separado.
* En el primer fotograma y las matrices de paso.

De esta manera, tenemos 6 maneras distintas de reconstruir nuestro vídeo.

```{r 6_a_funcion_compresion_paso_bajo, echo=FALSE}
#Aplicación de filtro paso bajo a un vídeo
comp_vid_paso_bajo <- function(video_frames_wavelet){
  video_frames_wavelet_compressed <- list()
  for (i in 1:length(video_frames_wavelet)){
    frame_r <- filtro2d_paso_bajo(video_frames_wavelet[[i]][[1]])
    frame_g <- filtro2d_paso_bajo(video_frames_wavelet[[i]][[2]])
    frame_b <- filtro2d_paso_bajo(video_frames_wavelet[[i]][[3]])
    fotograma <- list(frame_r,frame_g,frame_b)
    video_frames_wavelet_compressed <- c(video_frames_wavelet_compressed, list(fotograma))}
  return(video_frames_wavelet_compressed)
}
```

```{r 6_a_funcion_compresion_paso_bajo2, echo=FALSE}
#Aplicación de filtro paso bajo ajustable a un vídeo
comp_vid_paso_bajo2 <- function(video_frames_wavelet, q){
  video_frames_wavelet_compressed <- list()
  for (i in 1:length(video_frames_wavelet)){
    frame_r <- filtro2d_paso_bajo2(video_frames_wavelet[[i]][[1]],q)
    frame_g <- filtro2d_paso_bajo2(video_frames_wavelet[[i]][[2]],q)
    frame_b <- filtro2d_paso_bajo2(video_frames_wavelet[[i]][[3]],q)
    fotograma <- list(frame_r,frame_g,frame_b)
    video_frames_wavelet_compressed <- c(video_frames_wavelet_compressed, list(fotograma))}
  return(video_frames_wavelet_compressed)
}
```

```{r 6_a_funcion_reconstruccion, echo=FALSE}
#Reconstrucción del vídeo comprimido
rec_vid <- function(video_frames_wavelet_compressed, trans = FALSE){
  if (!trans) {
    video_frames <- list()
    for (i in 1:length(video_frames_wavelet_compressed)){
      frame_r <- idwt.2d(video_frames_wavelet_compressed[[i]][[1]])
      frame_g <- idwt.2d(video_frames_wavelet_compressed[[i]][[2]])
      frame_b <- idwt.2d(video_frames_wavelet_compressed[[i]][[3]])
      video_frames <- c(video_frames, list(array(c(frame_r, frame_g, frame_b), dim = c(dim(frame_r), 3))))
    }
  } else {
    frame_inicial_r <- idwt.2d(video_frames_wavelet_compressed[[1]][[1]])
    frame_inicial_g <- idwt.2d(video_frames_wavelet_compressed[[1]][[2]])
    frame_inicial_b <- idwt.2d(video_frames_wavelet_compressed[[1]][[3]])
    frame_inicial <- array(c(frame_inicial_r, frame_inicial_g, frame_inicial_b), dim = c(dim(frame_inicial_r), 3))
    video_frames <- list(frame_inicial)
    for (i in 2:length(video_frames_wavelet_compressed)){
      frame_r <- idwt.2d(video_frames_wavelet_compressed[[i]][[1]])
      frame_g <- idwt.2d(video_frames_wavelet_compressed[[i]][[2]])
      frame_b <- idwt.2d(video_frames_wavelet_compressed[[i]][[3]])
      video_frames <- c(video_frames, list(video_frames[[i-1]] + array(c(frame_r, frame_g, frame_b), dim = c(dim(frame_r), 3))))
    }
  }
  return(video_frames)
}
```

```{r 6_a_compresion_y_reconstruccion, echo=FALSE}
estatico_base <- rec_vid(dwt2d_videos[[1]], trans = FALSE)

estatico_base_trans <- rec_vid(dwt_trans_2d_videos[[1]], trans = TRUE)

estatico_wavelet_comprimido_paso_bajo <- comp_vid_paso_bajo(dwt2d_videos[[1]])
estatico_paso_bajo <- rec_vid(estatico_wavelet_comprimido_paso_bajo, trans = FALSE)

estatico_wavelet_comprimido_paso_bajo_trans <- comp_vid_paso_bajo(dwt_trans_2d_videos[[1]])
estatico_paso_bajo_trans <- rec_vid(estatico_wavelet_comprimido_paso_bajo_trans, trans = TRUE)

estatico_wavelet_comprimido_paso_bajo2 <- comp_vid_paso_bajo2(dwt2d_videos[[1]], q = 0.5)
estatico_paso_bajo2 <- rec_vid(estatico_wavelet_comprimido_paso_bajo2, trans = FALSE)

estatico_wavelet_comprimido_paso_bajo2_trans <- comp_vid_paso_bajo2(dwt_trans_2d_videos[[1]], q = 0.5)
estatico_paso_bajo2_trans <- rec_vid(estatico_wavelet_comprimido_paso_bajo2_trans, trans = TRUE)

giro_base <- rec_vid(dwt2d_videos[[2]], trans = FALSE)

giro_base_trans <- rec_vid(dwt_trans_2d_videos[[2]], trans = TRUE)

giro_wavelet_comprimido_paso_bajo <- comp_vid_paso_bajo(dwt2d_videos[[2]])
giro_paso_bajo <- rec_vid(giro_wavelet_comprimido_paso_bajo, trans = FALSE)

giro_wavelet_comprimido_paso_bajo_trans <- comp_vid_paso_bajo(dwt_trans_2d_videos[[2]])
giro_paso_bajo_trans <- rec_vid(giro_wavelet_comprimido_paso_bajo_trans, trans = TRUE)

giro_wavelet_comprimido_paso_bajo2 <- comp_vid_paso_bajo2(dwt2d_videos[[2]], q = 0.5)
giro_paso_bajo2 <- rec_vid(giro_wavelet_comprimido_paso_bajo2, trans = FALSE)

giro_wavelet_comprimido_paso_bajo2_trans <- comp_vid_paso_bajo2(dwt_trans_2d_videos[[2]], q = 0.5)
giro_paso_bajo2_trans <- rec_vid(giro_wavelet_comprimido_paso_bajo2_trans, trans = TRUE)
```

Adicionalmente, aplicaremos un método "análogo" al que hemos visto anteriormente en una dimensión cuando concatenábamos las señales fila o columna de una matriz. Esta vez organizaremos los fotogramas en una cuadrícula suficientemente grande y calcularemos la transformada wavelet a esta imagen resultante, para posteriormente aplicar los filtros apropiados que nos darán la compresión de esta imagen. Una vez hecho esto podremos recuperar los fotogramas a partir de la imagen para recomponer el vídeo.

```{r concatenate_and_split_frames_functions, echo=FALSE}
concatenate_frames <- function(video_frames) {
  # Número total de frames
  num_frames <- length(video_frames)
  
  # Dimensiones de las imágenes (se asume que todas son del mismo tamaño)
  frame_height <- dim(video_frames[[1]])[1]
  frame_width <- dim(video_frames[[1]])[2]
  
  # Calcular el siguiente cuadrado perfecto mayor o igual al número de frames
  sqrt_frames <- ceiling(sqrt(num_frames))
  total_frames <- sqrt_frames^2
  
  # Añadir frames negros si es necesario
  if (num_frames < total_frames) {
    black_frame <- array(0, dim = c(frame_height, frame_width, 3)) # Frame negro
    for (i in (num_frames + 1):total_frames) {
      video_frames[[i]] <- black_frame
    }
  }
  
  # Dimensión de la cuadrícula
  grid_dim <- sqrt_frames
  
  # Crear una imagen en blanco con el tamaño adecuado
  final_image <- array(0, dim = c(frame_height * grid_dim, frame_width * grid_dim, 3) )
  
  # Llenar la imagen final con los frames
  for (i in seq_along(video_frames)) {
    # Calcular la posición en la cuadrícula
    row <- (i - 1) %/% grid_dim
    col <- (i - 1) %% grid_dim
    
    # Extraer el frame actual
    current_frame <- video_frames[[i]]
    
    # Determinar la región donde colocar el frame
    row_start <- row * frame_height + 1
    row_end <- (row + 1) * frame_height
    col_start <- col * frame_width + 1
    col_end <- (col + 1) * frame_width
    
    # Insertar el frame en la imagen final
    final_image[row_start:row_end, col_start:col_end, ] <- current_frame
  }
  
  return(final_image)
}

split_frames <- function(concatenated_image, frame_height=256, frame_width=256) {
  # Dimensiones de la imagen concatenada
  image_height <- dim(concatenated_image)[1]
  image_width <- dim(concatenated_image)[2]
  
  # Calcular la cantidad de frames en la cuadrícula
  grid_rows <- image_height %/% frame_height
  grid_cols <- image_width %/% frame_width
  
  # Lista para almacenar los frames extraídos
  frames <- list()
  
  # Extraer cada frame de la imagen concatenada
  frame_index <- 1
  for (row in 0:(grid_rows - 1)) {
    for (col in 0:(grid_cols - 1)) {
      # Determinar la región del frame actual
      row_start <- row * frame_height + 1
      row_end <- (row + 1) * frame_height
      col_start <- col * frame_width + 1
      col_end <- (col + 1) * frame_width
      
      # Extraer el frame y agregarlo a la lista
      current_frame <- concatenated_image[row_start:row_end, col_start:col_end, ]
      frames[[frame_index]] <- current_frame
      frame_index <- frame_index + 1
    }
  }
  
  return(frames)
}
```

```{r concatenate_and_split_pruebas_1, echo=FALSE, include=FALSE}
concatenated_frames <- concatenate_frames(normalized_matrices_list[[1]])
visualizar_imagen_RGB(concatenated_frames)
```

```{r concatenate_and_split_pruebas_2, echo=FALSE, include=FALSE}
rows <- nrow(normalized_matrices_list[[1]][[1]])
cols <- ncol(normalized_matrices_list[[1]][[1]])
lista <- split_frames(concatenated_frames, rows , cols )
```

```{r comprimir_video_frames_concatenados, echo=FALSE}
compress_video_concat_frames <- function( frames , filtroQ = FALSE, q = -1, nivel=2 ){ #Frames debe ser una lista con cada elemento un fotograma en formato Matriz cuadrada RGB 
  
  N <- nrow( frames[[1]] )
  M <- ncol( frames[[1]] )
  
  if(N != M){
    mindim <- min( N , M )
      frames <- normalize_matrices( frames, mindim, mindim )
  }
  
  concatenated_frames <- concatenate_frames(frames)
  
  bn = as.logical( dim(frames[[1]])[3] %% 3 ) # ¿Es en blanco y negro?
  
  #Calculamos de dos maneras distintas la dwt
  
  dwt2d_frames_concat   <- aplic_dwt(concatenated_frames, bn = bn, wf= "haar", nivel=nivel) #dwt.2d 
  
  concat_frames_comprimida_2d   <- filtrar_dwt(dwt2d_frames_concat, bn = bn, filtroQ = filtroQ, q = q)
  
  concat_frames_reconstruida2d <- reconstruir_imag(concat_frames_comprimida_2d, bn=FALSE, dim= dim(concatenated_frames))
  concat_frames_concat_filas_1d   <- comp_concatenada_filas_RGB(concatenated_frames, filtro = "haar", niveles=nivel)
  
  splitted_frames_comp2d <- split_frames(concat_frames_reconstruida2d, frame_height= N, frame_width= M)
  splitted_frames_concat_filas_1d <- split_frames(concat_frames_concat_filas_1d, frame_height= N, frame_width= M)
  
  return( list( splitted_frames_comp2d , splitted_frames_concat_filas_1d) )
}
```

```{r transponer_90_grados, echo=FALSE}
rotate_frames_90 <- function(frames) {
  # Lista para almacenar los fotogramas rotados
  rotated_frames <- lapply(frames, function(frame) {
    # Rotar 90 grados equivale a transponer y luego invertir el orden de las filas
    apply(aperm(frame, c(2, 1, 3)), c(2, 3), rev)
  })
  
  return(rotated_frames)
}
```

```{r comprimir_video_frames_concatenados_prueba_1, echo=FALSE}
comprimido <- compress_video_concat_frames(normalized_matrices_list[[1]] )

comprimido_concat_2d <- comprimido[[1]]  #Comprime la cuadrícula de fotogramas mediante dwt.2d
comprimido_concat_1d <- comprimido[[2]]  #Comprime la cuadrícula de fotogrames mediante la dwt 1d al vector que concatena los píxeles
```

### b. Medición del error entre el video original y el comprimido.

La manera más clara de medir el error entre un vídeo y su compresión consiste en calcular el error entre los fotogramas del vídeo y normalizar dependiendo del número de fotogramas.

Sin embargo, dado que estamos utilizando métodos transicionales de compresión, es posible que el error se vaya acumulando de un fotograma a otro, resultando en un mayor error en el último fotograma.

Así pues, nuestra medición del error tendrá dos partes, una donde se calculara la diferencia general entre el vídeo original y el comprimido, y otra donde se vea el error presente en el último fotograma.

```{r 6_b_funcion_medición_error, echo=FALSE}
mse_vid <- function(vid1, vid2) {
  error <- 0
  for (i in 1:length(vid1)) {
    error <- error + mse_imags(vid1[[i]], vid2[[i]], bn = FALSE)
  }
  error <- error/(length(vid1))
  return(error)
}

error_compresion <- function(vid1, vid2) {
  cat("El error cuadrático entre los dos videos es",mse_vid(vid1, vid2),"\n")
  cat("El error cuadrático en el último fotograma es",mse_imags(vid1[[length(vid1)]], vid2[[length(vid1)]], bn = FALSE),"\n")
}
```

Veamos ahora el error que se obtiene al aplicar cada método de compresión en el vídeo "estatico".

```{r 6_b_comparacion_errores_estatico, echo=FALSE}
cat("","Método: Fotograma a fotograma sin compresión.","\n")
error_compresion(normalized_matrices_list[[1]],estatico_base)
cat("\n","Método: Matrices transicionales sin compresión.","\n")
error_compresion(normalized_matrices_list[[1]],estatico_base_trans)
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo.","\n")
error_compresion(normalized_matrices_list[[1]],estatico_paso_bajo)
cat("\n","Método: Matrices transicionales con filtro de paso bajo.","\n")
error_compresion(normalized_matrices_list[[1]],estatico_paso_bajo_trans)
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo 2 al 0.5.","\n")
error_compresion(normalized_matrices_list[[1]],estatico_paso_bajo2)
cat("\n","Método: Matrices transicionales con filtro de paso bajo 2 al 0.5.","\n")
error_compresion(normalized_matrices_list[[1]],estatico_paso_bajo2_trans)
cat("\n","Método: Cuadrícula de los fotogramas con filtro con dwt.2d de paso bajo 2.","\n")
error_compresion(normalized_matrices_list[[1]],comprimido_concat_2d)
cat("\n","Método: Cuadrícula de los fotogramas con filtro con dwt 1d al vector concatenado","\n")
error_compresion(normalized_matrices_list[[1]],comprimido_concat_1d)
```

Todos los métodos tienen un error relativamente bajo, que indica que los métodos de compresión son capaces de mantener la fidelidad del video original.

Veamos ahora el error que se obtiene al aplicar cada método de compresión en el vídeo "giro".

```{r 6_b_comparacion_errores_giro, echo=FALSE}
cat("","Método: Fotograma a fotograma sin compresión.","\n")
error_compresion(normalized_matrices_list[[2]],giro_base)
cat("\n","Método: Matrices transicionales sin compresión.","\n")
error_compresion(normalized_matrices_list[[2]],giro_base_trans)
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo.","\n")
error_compresion(normalized_matrices_list[[2]],giro_paso_bajo)
cat("\n","Método: Matrices transicionales con filtro de paso bajo.","\n")
error_compresion(normalized_matrices_list[[2]],giro_paso_bajo_trans)
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo 2 al 0.5.","\n")
error_compresion(normalized_matrices_list[[2]],giro_paso_bajo2)
cat("\n","Método: Matrices transicionales con filtro de paso bajo 2 al 0.5.","\n")
error_compresion(normalized_matrices_list[[2]],giro_paso_bajo2_trans)
```

De nuevo, vemos que la compresión no ha afectado gravemente a la fidelidad del vídeo. Además, sorprendentemente, no parece que el método transicional haya afectado mucho a la calidad del último fotograma.

### c. Analizar el nivel de compresión.

Nuestros métodos de compresión funcionaban sustituyendo puntos de las matrices de detalle y aproximación de nuestra transformada wavelet por 0. Así, para medir el grado de compresión de cada método, calcularemos el porcentaje de ceros existentes en nuestros coeficientes wavelet.

```{r 6_c_medición_compresion, echo=FALSE}
proporcion_ceros <- function(wavelet_comprimido, nivel=2) {
  zeros <- 0
  for (i in 1:length(wavelet_comprimido)) {
    for (j in 1:3){
      for (k in 1:3*nivel){
        zeros <- zeros + sum(wavelet_comprimido[[i]][[j]][[k]] == 0)
      }
    }
  }
  proporcion <- zeros/(((dim(wavelet_comprimido[[1]][[1]][[1]])[1]*2)^2)*length(wavelet_comprimido))
  return(proporcion)
}
```

A continuación, estudiaremos la compresión presente usando nuestros distintos métodos en el vídeo estatico.

```{r 6_c_comparacion_compresion_estatico, echo=FALSE}
cat("","Método: Fotograma a fotograma sin compresión.","\n")
cat("","Ratio de compresión:",proporcion_ceros(dwt2d_videos[[1]])*100,"%")
cat("\n","Método: Matrices transicionales sin compresión.","\n")
cat("","Ratio de compresión:",proporcion_ceros(dwt_trans_2d_videos[[1]])*100,"%")
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo.","\n")
cat("","Ratio de compresión:",proporcion_ceros(estatico_wavelet_comprimido_paso_bajo)*100,"%")
cat("\n","Método: Matrices transicionales con filtro de paso bajo.","\n")
cat("","Ratio de compresión:",proporcion_ceros(estatico_wavelet_comprimido_paso_bajo_trans)*100,"%")
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo 2 al 0.5.","\n")
cat("","Ratio de compresión:",proporcion_ceros(estatico_wavelet_comprimido_paso_bajo2)*100,"%")
cat("\n","Método: Matrices transicionales con filtro de paso bajo 2 al 0.5.","\n")
cat("","Ratio de compresión:",proporcion_ceros(estatico_wavelet_comprimido_paso_bajo2_trans)*100,"%")
```

Por comprobar que nuestro código es consisitente, estudiaremos la compresión presente usando nuestros distintos métodos en el vídeo giro.

```{r 6_c_comparacion_compresion_giro, echo=FALSE}
cat("","Método: Fotograma a fotograma sin compresión.","\n")
cat("","Ratio de compresión:",proporcion_ceros(dwt2d_videos[[2]])*100,"%")
cat("\n","Método: Matrices transicionales sin compresión.","\n")
cat("","Ratio de compresión:",proporcion_ceros(dwt_trans_2d_videos[[2]])*100,"%")
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo.","\n")
cat("","Ratio de compresión:",proporcion_ceros(giro_wavelet_comprimido_paso_bajo)*100,"%")
cat("\n","Método: Matrices transicionales con filtro de paso bajo.","\n")
cat("","Ratio de compresión:",proporcion_ceros(giro_wavelet_comprimido_paso_bajo_trans)*100,"%")
cat("\n","Método: Fotograma a fotograma con filtro de paso bajo 2 al 0.5.","\n")
cat("","Ratio de compresión:",proporcion_ceros(giro_wavelet_comprimido_paso_bajo2)*100,"%")
cat("\n","Método: Matrices transicionales con filtro de paso bajo 2 al 0.5.","\n")
cat("","Ratio de compresión:",proporcion_ceros(giro_wavelet_comprimido_paso_bajo2_trans)*100,"%")
```

Como podemos observar, apenas hay compresión cuando no aplicamos ningún método de compresión, obviamente. El pequeño porcentaje tan solo aparece por la presencia de ceros naturales en los coeficientes.

Por otro lado, el filtro de paso bajo usual aplica una compresión de alrededor de 75%, ya que elimina tres submatrices de detalle de la mitad de la longitud original.

Por último, el filtro de paso bajo aplica una compresión de un 37%, aunque este factor es completamente dependiente de nuestro umbral de compresión aplicado. En nuestro caso, esta compresión es igual a 37% porqué hemos usado un factor de 0.5, es decir, la mitad de 75%, la máxima compresión previa.


